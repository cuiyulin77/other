# -*- coding: utf-8 -*-
import scrapy
import json
from somenew.items import SomenewItem
from copy import deepcopy
import hashlib
import datetime

# 获取cctv经济频道的最新报道 http://jingji.cctv.com/
class CctvJjSpider(scrapy.Spider):
    name = 'cctv_jj'
    allowed_domains = ['cctv.com']
    start_urls = ['http://jingji.cctv.com/data/index.json?']

    def parse(self, response):
        ret = response.body.decode()
        dict = json.loads(ret)
        data_list = dict['rollData']
        for data in data_list:
            item = SomenewItem()
            item['url'] = data['url']
            item['time'] = data['dateTime']
            item['title'] = data['title']
            yield scrapy.Request(item['url'],callback=self.get_content,meta={'item':deepcopy(item)})

    def get_content(self,response):
        item=response.meta['item']
        item['media'] = '央视经济'
        # content=response.xpath("//div[@class='cnt_bd']")
        item['content']=response.xpath("//div[@class='cnt_bd']//p//text()").extract()
        item['content'] = ''.join(item["content"]).replace(u'\u3000', u' ').replace(u'\xa0', u' ').replace("\n",'  ')
        # item['content'] = content[0].xpath('string(.)').extract()[0].replace('\n', '').replace('\t', ' ')
        item['create_time'] = datetime.datetime.now().strftime('%Y/%m/%d %H:%M:%S')
        m = hashlib.md5()
        url = str(item['url'])
        m.update(str(url).encode('utf8'))
        article_id = str(m.hexdigest())
        item['article_id'] = article_id
        item['comm_num'] = "0"
        item['fav_num'] = '0'
        item['read_num'] = '0'
        item['env_num'] = '0'
        item['media_type'] = '网媒'
        yield item

